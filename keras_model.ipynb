{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPMrHbKn/fhjdkAGDam2Vb0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/baloochyb/TensorFlow/blob/main/keras_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lzggRy6Vzeao"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.python.keras.models import load_model\n",
        "# from tensorflow.python.keras import backend as k\n",
        "\n",
        "# print(tf.keras.__version__)\n",
        "# const = k.constant([[42,24],[11,99]], dtype=tf.float16, shape=[2,2])\n",
        "# print(const)\n",
        "# Prepare Data\n",
        "mnist = tf.keras.datasets.mnist\n",
        "(train_x,train_y), (test_x, test_y) = mnist.load_data()\n",
        "epochs=10\n",
        "batch_size = 32 # 32 is default in fit method but specify anyway\n",
        "train_x, test_x = tf.cast(train_x/255.0, tf.float32), tf.cast(test_x/255.0, tf.float32)\n",
        "train_y, test_y = tf.cast(train_y,tf.int64), tf.cast(test_y,tf.int64)\n",
        "\n",
        "# Build Model (First Method) --------------------------------------------------------\n",
        "\n",
        "model1 = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
        "])\n",
        "model1.summary()\n",
        "# Compile Model\n",
        "optimiser = tf.keras.optimizers.Adam()\n",
        "model1.compile(optimizer=optimiser, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "# Fit Model\n",
        "model1.fit(train_x, train_y, batch_size=batch_size, epochs=epochs)\n",
        "# Evaluate Mosel\n",
        "model1.evaluate(test_x, test_y)\n",
        "\n",
        "# An alternative method --------------------------------------------------------------\n",
        "\n",
        "model2 = tf.keras.models.Sequential()\n",
        "model2.add(tf.keras.layers.Flatten())\n",
        "model2.add(tf.keras.layers.Dense(512, activation='relu'))\n",
        "model2.add(tf.keras.layers.Dropout(0.2))\n",
        "model2.add(tf.keras.layers.Dense(10,activation=tf.nn.softmax))\n",
        "\n",
        "model2.compile(optimizer=optimiser, loss='sparse_categorical_crossentropy', metrics = ['accuracy'])\n",
        "\n",
        "model2.fit(train_x, train_y, batch_size=batch_size, epochs=epochs)\n",
        "\n",
        "model2.evaluate(test_x, test_y)\n",
        "\n",
        "# An alternative method --------------------------------------------------------------\n",
        "\n",
        "inputs = tf.keras.Input(shape=(28,28)) # Returns a 'placeholder' tensor\n",
        "x = tf.keras.layers.Flatten()(inputs)\n",
        "x = tf.keras.layers.Dense(512, activation='relu',name='d1')(x)\n",
        "x = tf.keras.layers.Dropout(0.2)(x)\n",
        "predictions = tf.keras.layers.Dense(10,activation=tf.nn.softmax, name='d2')(x)\n",
        "model3 = tf.keras.Model(inputs=inputs, outputs=predictions)\n",
        "\n",
        "# Subclassing the Keras Model ---------------------------------------------------------\n",
        "\n",
        "class MyModel(tf.keras.Model):\n",
        "    def __init__(self, num_classes=10):\n",
        "        super(MyModel, self).__init__()\n",
        "    # Define your layers here.\n",
        "        inputs = tf.keras.Input(shape=(28,28)) # Returns a placeholder tensor\n",
        "        self.x0 = tf.keras.layers.Flatten()\n",
        "        self.x1 = tf.keras.layers.Dense(512, activation='relu',name='d1')\n",
        "        self.x2 = tf.keras.layers.Dropout(0.2)\n",
        "        self.predictions = tf.keras.layers.Dense(10,activation=tf.nn.softmax, name='d2')\n",
        "    def call(self, inputs):\n",
        "    # This is where to define your forward pass\n",
        "    # using the layers previously defined in `__init__`\n",
        "        x = self.x0(inputs)\n",
        "        x = self.x1(x)\n",
        "        x = self.x2(x)\n",
        "        return self.predictions(x)\n",
        "\n",
        "model4 = MyModel()\n",
        "\n",
        "model4 = MyModel()\n",
        "batch_size = 32\n",
        "steps_per_epoch = len(train_x.numpy())//batch_size\n",
        "print(steps_per_epoch)\n",
        "model4.compile (optimizer= tf.keras.optimizers.Adam(), loss='sparse_categorical_crossentropy', metrics = ['accuracy'])\n",
        "model4.fit(train_x, train_y, batch_size=batch_size, epochs=epochs)\n",
        "model4.evaluate(test_x, test_y)\n",
        "\n",
        "# data pipelines -----------------------------------------------------------------------\n",
        "\n",
        "batch_size = 32\n",
        "buffer_size = 10000\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((train_x, train_y)).batch(batch_size).shuffle(buffer_size)\n",
        "train_dataset = train_dataset.map(lambda x, y: (tf.image.random_flip_left_right(x), y))\n",
        "train_dataset = train_dataset.repeat()\n",
        "\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((test_x, test_y)).batch(batch_size).shuffle(buffer_size)\n",
        "test_dataset = train_dataset.repeat()\n",
        "\n",
        "steps_per_epoch = len(train_x)//batch_size # required because of the repeat on the dataset\n",
        "optimiser = tf.keras.optimizers.Adam()\n",
        "model4.compile (optimizer= optimiser, loss='sparse_categorical_crossentropy', metrics = ['accuracy'])\n",
        "model4.fit(train_dataset, batch_size=batch_size, epochs=epochs, steps_per_epoch=steps_per_epoch)\n",
        "\n",
        "# Saving and loading Keras models\n",
        "\n",
        "model4.save('./model_name.h5')\n",
        "new_model = load_model('./model_name.h5')\n",
        "\n",
        "model3.save_weights('./model_weights.h5')\n",
        "model3.load_weights('./model_weights.h5')\n"
      ]
    }
  ]
}